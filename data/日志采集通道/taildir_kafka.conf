#为各个组件命名
a1.sources = r1	
a1.channels = c1 c2

#描述source
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /tmp/logs/app.*
#配置断点续传
a1.sources.r1.positionFile = /opt/module/flume-1.7.0/taildir_position.json
#配置选择器
a1.sources.r1.selector.type = multiplexing
a1.sources.r1.selector.header = topic
a1.sources.r1.selector.mapping.topic_start = c1
a1.sources.r1.selector.mapping.topic_event = c2
#配置拦截器
a1.sources.r1.interceptors = i1 i2
#先etl
a1.sources.r1.interceptors.i1.type = com.xstudio.gmall.flume.interceptor.ETLInterceptor$Builder
#再打标签
a1.sources.r1.interceptors.i2.type = com.xstudio.gmall.flume.interceptor.TypeInterceptor$Builder
#描述channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = hadoop105:9092,hadoop106:9092
a1.channels.c1.kafka.topic = topic_start
#进入kafka不保留event

a1.channels.c1.parseAsFlumeEvent = false
a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c2.kafka.bootstrap.servers = hadoop105:9092,hadoop106:9092
a1.channels.c2.kafka.topic = topic_event
#进入kafka不保留event
a1.channels.c2.parseAsFlumeEvent = false

#绑定source和channel
a1.sources.r1.channels = c1 c2
